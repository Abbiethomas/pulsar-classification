{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulsar Classification using ANN\n",
    "Abbie Thomas<br>\n",
    "Kunho Kim<br>\n",
    "May 11, 2021<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read csv file into dataframe\n",
    "df = pd.read_csv(filepath_or_buffer=\"HTRU_2.csv\",header=0)\n",
    "df = df.rename(columns={\"140.5625\": \"a\", \"55.68378214\": \"b\",\n",
    "                       \"-0.234571412\": \"c\", \"-0.699648398\": \"d\", \n",
    "                       \"3.199832776\": \"e\", \"19.11042633\": \"f\", \n",
    "                       \"7.975531794\": \"g\", \"74.24222492\": \"h\",\n",
    "                       \"0\": \"class\"})\n",
    "df = df.append({'a': 140.5625, 'b': 55.68378214, 'c': -0.234571412, 'd': -0.699648398,\n",
    "               'e': 3.199832776, 'f': 19.11042633, 'g': 7.975531794, 'h': 74.24222492,\n",
    "               'class': 0}, ignore_index=True)\n",
    "x = df.values[:,0:-1]\n",
    "y = df.values[:,-1].ravel()\n",
    "\n",
    "# Initialise the Scaler\n",
    "scaler = StandardScaler()\n",
    "  \n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "type(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(x_scaled, y, test_size = 0.20)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13041    0.0\n",
      "917      0.0\n",
      "16514    0.0\n",
      "2132     0.0\n",
      "9069     0.0\n",
      "        ... \n",
      "14728    0.0\n",
      "3745     0.0\n",
      "11208    0.0\n",
      "12288    0.0\n",
      "3013     0.0\n",
      "Name: class, Length: 8129, dtype: float64\n",
      "3174     0.0\n",
      "17622    0.0\n",
      "17320    0.0\n",
      "14450    0.0\n",
      "17572    0.0\n",
      "        ... \n",
      "15544    0.0\n",
      "12820    0.0\n",
      "1640     0.0\n",
      "7666     0.0\n",
      "9957     0.0\n",
      "Name: class, Length: 8130, dtype: float64\n",
      "3620     1.0\n",
      "10897    1.0\n",
      "3117     1.0\n",
      "5679     1.0\n",
      "4067     1.0\n",
      "        ... \n",
      "5320     1.0\n",
      "5660     1.0\n",
      "9764     1.0\n",
      "4104     1.0\n",
      "4820     1.0\n",
      "Name: class, Length: 1311, dtype: float64\n",
      "13933    1.0\n",
      "10904    1.0\n",
      "7509     1.0\n",
      "9398     1.0\n",
      "4016     1.0\n",
      "        ... \n",
      "8778     1.0\n",
      "5080     1.0\n",
      "12729    1.0\n",
      "11281    1.0\n",
      "400      1.0\n",
      "Name: class, Length: 328, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Representative sample with 15% of training data being pulsar and 4% of test data being pulsars.\n",
    "\n",
    "df0 = df.loc[df['class'] == 0]\n",
    "df1 = df.loc[df['class'] == 1]\n",
    "\n",
    "x1 = df1.iloc[:,0:-1]\n",
    "y1 = df1.iloc[:,-1]\n",
    "\n",
    "x0 = df0.iloc[:,0:-1]\n",
    "y0 = df0.iloc[:,-1]\n",
    "\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(x0, y0, test_size = 0.5, random_state = 0)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, train_size = 0.80, random_state = 0)\n",
    "\n",
    "X_train_rep = X_train1.append(X_train0)\n",
    "X_test_rep = X_test1.append(X_test0)\n",
    "y_train_rep = y_train1.append(y_train0)\n",
    "y_test_rep = y_test1.append(y_test0)\n",
    "\n",
    "#print(y_train_rep)\n",
    "print(y_train_rep.loc[y_train_rep == 0])\n",
    "print(y_test_rep.loc[y_test_rep == 0])\n",
    "\n",
    "print(y_train_rep.loc[y_train_rep == 1])\n",
    "print(y_test_rep.loc[y_test_rep == 1])\n",
    "\n",
    "X_train_rep = scaler.fit_transform(X_train_rep)\n",
    "X_test_rep = scaler.fit_transform(X_test_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Processing data...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read in data\n",
    "\"\"\"\n",
    "print(\"Reading data...\")\n",
    "# df = pd.read_csv('HTRU_2.csv')\n",
    "df0 = pd.read_csv('data0.csv')\n",
    "df1 = pd.read_csv('data1.csv')\n",
    "\n",
    "df0 = df0.sample(n=len(df1), random_state = 0)\n",
    "\n",
    "\"\"\"\n",
    "Preprocess and data preparation\n",
    "\"\"\"\n",
    "print(\"Processing data...\")\n",
    "\n",
    "pre_features_0 = df0.iloc[: , :8]\n",
    "pre_target_0 = df0['class']\n",
    "\n",
    "# rescale variables to have 0 mean and unit variance\n",
    "df_columns_0 = pre_features_0.columns\n",
    "scaler = StandardScaler()\n",
    "scaledf_0 = scaler.fit_transform(pre_features_0)\n",
    "\n",
    "pre_features_1 = df1.iloc[: , :8]\n",
    "pre_target_1 = df1['class']\n",
    "\n",
    "# rescale variables to have 0 mean and unit variance\n",
    "df_columns_1 = pre_features_1.columns\n",
    "scaledf_1 = scaler.fit_transform(pre_features_1)\n",
    "\n",
    "# restructure dataframe\n",
    "df0 = pd.DataFrame(scaledf_0)\n",
    "df0.columns = df_columns_0\n",
    "df0['class'] = pre_target_0\n",
    "df0['class'] = df0['class'].fillna(0).astype(np.int64)\n",
    "\n",
    "df1 = pd.DataFrame(scaledf_1)\n",
    "df1.columns = df_columns_1\n",
    "df1['class'] = pre_target_1\n",
    "\n",
    "# reassign feature and targets to newly scaled variables\n",
    "features_0 = df0.iloc[:, :8]\n",
    "target_0 = df0['class']\n",
    "\n",
    "features_1 = df1.iloc[:, :8]\n",
    "target_1 = df1['class']\n",
    "\n",
    "# pre_features = df.iloc[: , :8]\n",
    "# pre_target = df['class']\n",
    "\n",
    "# # rescale variables to have 0 mean and unit variance\n",
    "# df_columns = pre_features.columns\n",
    "# scaler = StandardScaler()\n",
    "# scaledf = scaler.fit_transform(pre_features)\n",
    "\n",
    "# # restructure dataframe\n",
    "# df = pd.DataFrame(scaledf)\n",
    "# df.columns = df_columns\n",
    "# df['class'] = pre_target\n",
    "\n",
    "# # reassign feature and targets to newly scaled variables\n",
    "# features = df.iloc[:, :8]\n",
    "# target = df['class']\n",
    "\n",
    "# split dataset into test and train split\n",
    "# 80/20 split\n",
    "feat_train_0, feat_test_0, target_train_0, target_test_0 = train_test_split(features_0, target_0, train_size = 0.8, random_state = 0)\n",
    "feat_train_1, feat_test_1, target_train_1, target_test_1 = train_test_split(features_1, target_1, train_size = 0.8, random_state = 0)\n",
    "\n",
    "feat_train = feat_train_0.append(feat_train_1)\n",
    "feat_test = feat_test_0.append(feat_test_1)\n",
    "target_train = target_train_0.append(target_train_1)\n",
    "target_test = target_test_0.append(target_test_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_del = df0.iloc[0:1639, 0:-1]\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(x0, y0, test_size = 0.2, random_state = 0)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, train_size = 0.80, random_state = 0)\n",
    "\n",
    "X_train_rep_del = X_train1.append(X_train0)\n",
    "X_test_rep_del = X_test1.append(X_test0)\n",
    "y_train_rep_del = y_train1.append(y_train0)\n",
    "y_test_rep_del = y_test1.append(y_test0)\n",
    "\n",
    "X_train_rep_del = scaler.fit_transform(X_train_rep_del)\n",
    "X_test_rep_del = scaler.fit_transform(X_test_rep_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.976184\n",
      "Test set score: 0.975978\n",
      "[[3223   23]\n",
      " [  63  271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3246\n",
      "         1.0       0.92      0.81      0.86       334\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.95      0.90      0.92      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with unscaled data\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp.coefs_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.980235\n",
      "Test set score: 0.979609\n",
      "[[3210   11]\n",
      " [  62  297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3221\n",
      "         1.0       0.96      0.83      0.89       359\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.97      0.91      0.94      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data\n",
    "\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(8,8))\n",
    "mlp2.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp2.score(X_train_scaled, y_train_scaled))\n",
    "print(\"Test set score: %f\" % mlp2.score(X_test_scaled, y_test_scaled))\n",
    "\n",
    "predictions = mlp2.predict(X_test_scaled)\n",
    "\n",
    "print(confusion_matrix(y_test_scaled,predictions))\n",
    "print(classification_report(y_test_scaled,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp2.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.981003\n",
      "Test set score: 0.978492\n",
      "[[3206   15]\n",
      " [  62  297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3221\n",
      "         1.0       0.95      0.83      0.89       359\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.97      0.91      0.94      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data and logistic sigmoid activation function\n",
    "\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(8,8),activation='logistic')\n",
    "mlp3.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp3.score(X_train_scaled, y_train_scaled))\n",
    "print(\"Test set score: %f\" % mlp3.score(X_test_scaled, y_test_scaled))\n",
    "\n",
    "predictions = mlp3.predict(X_test_scaled)\n",
    "\n",
    "print(confusion_matrix(y_test_scaled,predictions))\n",
    "print(classification_report(y_test_scaled,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp3.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.980724\n",
      "Test set score: 0.979050\n",
      "[[3206   15]\n",
      " [  60  299]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      3221\n",
      "         1.0       0.95      0.83      0.89       359\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.97      0.91      0.94      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data and hyperbolic tangent activation function\n",
    "\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(8,8),activation='tanh')\n",
    "mlp4.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp4.score(X_train_scaled, y_train_scaled))\n",
    "print(\"Test set score: %f\" % mlp4.score(X_test_scaled, y_test_scaled))\n",
    "\n",
    "predictions = mlp4.predict(X_test_scaled)\n",
    "\n",
    "print(confusion_matrix(y_test_scaled,predictions))\n",
    "print(classification_report(y_test_scaled,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp4.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.975530\n",
      "Test set score: 0.931544\n",
      "[[7577  553]\n",
      " [  26  302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96      8130\n",
      "         1.0       0.35      0.92      0.51       328\n",
      "\n",
      "    accuracy                           0.93      8458\n",
      "   macro avg       0.67      0.93      0.74      8458\n",
      "weighted avg       0.97      0.93      0.95      8458\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data and representative data\n",
    "\n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(8,8))\n",
    "mlp5.fit(X_train_rep, y_train_rep)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp5.score(X_train_rep, y_train_rep))\n",
    "print(\"Test set score: %f\" % mlp5.score(X_test_rep, y_test_rep))\n",
    "\n",
    "predictions = mlp5.predict(X_test_rep)\n",
    "\n",
    "print(confusion_matrix(y_test_rep,predictions))\n",
    "print(classification_report(y_test_rep,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp5.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.998856\n",
      "Test set score: 1.000000\n",
      "[[328   0]\n",
      " [  0 328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       328\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00       656\n",
      "   macro avg       1.00      1.00      1.00       656\n",
      "weighted avg       1.00      1.00      1.00       656\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data and representative data and hyperbolic tangent activation function\n",
    "\n",
    "mlp6 = MLPClassifier(hidden_layer_sizes=(8,8),activation='tanh')\n",
    "mlp6.fit(feat_train, target_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp6.score(feat_train, target_train))\n",
    "print(\"Test set score: %f\" % mlp6.score(feat_test, target_test))\n",
    "\n",
    "predictions = mlp6.predict(feat_test)\n",
    "\n",
    "print(confusion_matrix(target_test,predictions))\n",
    "print(classification_report(target_test,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp6.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.980514\n",
      "Test set score: 0.977933\n",
      "[[3230   22]\n",
      " [  57  271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      3252\n",
      "         1.0       0.92      0.83      0.87       328\n",
      "\n",
      "    accuracy                           0.98      3580\n",
      "   macro avg       0.95      0.91      0.93      3580\n",
      "weighted avg       0.98      0.98      0.98      3580\n",
      "\n",
      "Coefficients\n",
      "[(8, 8), (8, 8), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Standard Classifier with scaled data and rep_delresentative data and hyperbolic tangent activation function\n",
    "\n",
    "mlp7 = MLPClassifier(hidden_layer_sizes=(8,8),activation='tanh')\n",
    "mlp7.fit(X_train_rep_del, y_train_rep_del)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp7.score(X_train_rep_del, y_train_rep_del))\n",
    "print(\"Test set score: %f\" % mlp7.score(X_test_rep_del, y_test_rep_del))\n",
    "\n",
    "predictions = mlp7.predict(X_test_rep_del)\n",
    "\n",
    "print(confusion_matrix(y_test_rep_del,predictions))\n",
    "print(classification_report(y_test_rep_del,predictions))\n",
    "\n",
    "print(\"Coefficients\")\n",
    "print([coef.shape for coef in mlp7.coefs_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#dataset import\n",
    "df = pd.read_csv('./project1/HTRU_2.csv') #You need to change #directory accordingly\n",
    "\n",
    "title = list(df.columns.values)\n",
    "features = title[:-1]\n",
    "X = df.iloc[:, :8].values\n",
    "y = df.iloc[:, 8:9].values\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)\n",
    "\n",
    "#Building ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 8, activation = 'sigmoid'))\n",
    "# model.add(Dense(8, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#loss function and optimizer\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "#training\n",
    "history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs = 100, batch_size = 64)\n",
    "\n",
    "#testing\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))\n",
    "    \n",
    "#accuracy\n",
    "a = accuracy_score(pred, test)\n",
    "print(\"Accuracy:\", a*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 12.46133428\n",
      "Iteration 2, loss = 17.91379792\n",
      "Iteration 3, loss = 18.05575663\n",
      "Iteration 4, loss = 18.06213126\n",
      "Iteration 5, loss = 18.06080540\n",
      "Iteration 6, loss = 18.05957087\n",
      "Iteration 7, loss = 18.05833816\n",
      "Iteration 8, loss = 18.05695909\n",
      "Iteration 9, loss = 18.05566317\n",
      "Iteration 10, loss = 18.05434847\n",
      "Training set score: 0.908856\n",
      "Test set score: 0.906704\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                            module=\"sklearn\")\n",
    "    mlp2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp2.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
